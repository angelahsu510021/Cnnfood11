{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport os\nimport numpy as np\nimport cv2\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport pandas as pd\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nimport time","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:14:30.678025Z","iopub.execute_input":"2021-06-02T08:14:30.678439Z","iopub.status.idle":"2021-06-02T08:14:32.009635Z","shell.execute_reply.started":"2021-06-02T08:14:30.678360Z","shell.execute_reply":"2021-06-02T08:14:32.008805Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def readfile(path, label):\n    # label 是一個 boolean variable，代表需不需要回傳 y 值\n    image_dir = sorted(os.listdir(path))\n    x = np.zeros((len(image_dir), 128, 128, 3), dtype=np.uint8)\n    y = np.zeros((len(image_dir)), dtype=np.uint8)\n    for i, file in enumerate(image_dir):\n        img = cv2.imread(os.path.join(path, file))\n        x[i, :, :] = cv2.resize(img,(128, 128))\n        if label:\n          y[i] = int(file.split(\"_\")[0])\n    if label:\n      return x, y\n    else:\n      return x","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:14:32.011276Z","iopub.execute_input":"2021-06-02T08:14:32.011615Z","iopub.status.idle":"2021-06-02T08:14:32.018472Z","shell.execute_reply.started":"2021-06-02T08:14:32.011580Z","shell.execute_reply":"2021-06-02T08:14:32.017649Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"workspace_dir = '../input/food11'\nprint(\"Reading data\")\n#train_x, train_y = readfile(os.path.join(workspace_dir, \"training\"), True)\n#print(\"Size of training data = {}\".format(len(train_x)))\n#val_x, val_y = readfile(os.path.join(workspace_dir, \"validation\"), True)\n#print(\"Size of validation data = {}\".format(len(val_x)))\ntest_x = readfile(os.path.join(workspace_dir, \"evaluation\"), False)\nprint(\"Size of Testing data = {}\".format(len(test_x)))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:14:32.020254Z","iopub.execute_input":"2021-06-02T08:14:32.020606Z","iopub.status.idle":"2021-06-02T08:15:16.125281Z","shell.execute_reply.started":"2021-06-02T08:14:32.020571Z","shell.execute_reply":"2021-06-02T08:15:16.124247Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Reading data\nSize of Testing data = 3347\n","output_type":"stream"}]},{"cell_type":"code","source":"# testing 時不需做 data augmentation\ntest_transform = transforms.Compose([\n    transforms.ToPILImage(),                                    \n    transforms.ToTensor(),\n])\nclass ImgDataset(Dataset):\n    def __init__(self, x, y=None, transform=None):\n        self.x = x\n        # label is required to be a LongTensor\n        self.y = y\n        if y is not None:\n            self.y = torch.LongTensor(y)\n        self.transform = transform\n    def __len__(self):\n        return len(self.x)\n    def __getitem__(self, index):\n        X = self.x[index]\n        if self.transform is not None:\n            X = self.transform(X)\n        if self.y is not None:\n            Y = self.y[index]\n            return X, Y\n        else:\n            return X","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:01.082037Z","iopub.execute_input":"2021-06-02T08:19:01.082393Z","iopub.status.idle":"2021-06-02T08:19:01.089171Z","shell.execute_reply.started":"2021-06-02T08:19:01.082362Z","shell.execute_reply":"2021-06-02T08:19:01.088218Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"batch_size = 64","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:03.540137Z","iopub.execute_input":"2021-06-02T08:19:03.540478Z","iopub.status.idle":"2021-06-02T08:19:03.544728Z","shell.execute_reply.started":"2021-06-02T08:19:03.540440Z","shell.execute_reply":"2021-06-02T08:19:03.543794Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n        # input 維度 [3, 128, 128]\n        self.cnn = nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),  # [64, 128, 128]\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [64, 64, 64]\n\n            nn.Conv2d(64, 128, 3, 1, 1), # [128, 64, 64]\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [128, 32, 32]\n\n            nn.Dropout2d(0.5),\n\n            nn.Conv2d(128, 256, 3, 1, 1), # [256, 32, 32]\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),      # [256, 16, 16]\n\n            nn.Conv2d(256, 512, 3, 1, 1), # [512, 16, 16]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 8, 8]\n\n            nn.Dropout2d(0.3),\n            \n            nn.Conv2d(512, 512, 3, 1, 1), # [512, 8, 8]\n            nn.BatchNorm2d(512),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),       # [512, 4, 4]\n        )\n        self.fc = nn.Sequential(\n            nn.Linear(512*4*4, 1024),\n            nn.ReLU(),\n            \n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            \n            nn.Linear(512, 256),\n            nn.ReLU(),\n            \n            nn.Linear(256, 128),\n            nn.Linear(128, 11),\n            nn.ReLU(),\n        )\n\n    def forward(self, x):\n        out = self.cnn(x)\n        out = out.view(out.size()[0], -1)\n        return self.fc(out)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:05.738922Z","iopub.execute_input":"2021-06-02T08:19:05.739260Z","iopub.status.idle":"2021-06-02T08:19:05.750496Z","shell.execute_reply.started":"2021-06-02T08:19:05.739229Z","shell.execute_reply":"2021-06-02T08:19:05.749414Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test_set = ImgDataset(test_x, transform=test_transform)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:10.075830Z","iopub.execute_input":"2021-06-02T08:19:10.076177Z","iopub.status.idle":"2021-06-02T08:19:10.080454Z","shell.execute_reply.started":"2021-06-02T08:19:10.076141Z","shell.execute_reply":"2021-06-02T08:19:10.079376Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"model_best = Classifier().cuda()\nmodel_best.load_state_dict(torch.load('../input/modelbest5/model_best5.pth'))\nmodel_best.eval()\nprediction = []\nwith torch.no_grad():\n    for i, data in enumerate(test_loader):\n        test_pred = model_best(data.cuda())\n        test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n        for y in test_label:\n            prediction.append(y)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:11.661599Z","iopub.execute_input":"2021-06-02T08:19:11.661921Z","iopub.status.idle":"2021-06-02T08:19:14.218026Z","shell.execute_reply.started":"2021-06-02T08:19:11.661891Z","shell.execute_reply":"2021-06-02T08:19:14.217205Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"#將結果寫入 csv 檔 kaggle\nwith open(\"predict5.csv\", 'w') as f:\n    f.write('Id,Category\\n')\n    for i, y in  enumerate(prediction):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T08:19:18.545812Z","iopub.execute_input":"2021-06-02T08:19:18.546198Z","iopub.status.idle":"2021-06-02T08:19:18.556506Z","shell.execute_reply.started":"2021-06-02T08:19:18.546163Z","shell.execute_reply":"2021-06-02T08:19:18.555574Z"},"trusted":true},"execution_count":24,"outputs":[]}]}